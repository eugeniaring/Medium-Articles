{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import libraries"
      ],
      "metadata": {
        "id": "gb6gKZcV5bmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fPBKRcM5h8Y",
        "outputId": "fb83fa16-03c8-4597-c0d3-8f90db613a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stm_Itv85kAM",
        "outputId": "cbc8e701-5398-4fe0-a8a2-522b1f8fec71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.266)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.22)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIF_XWTL5pYx",
        "outputId": "8633dcba-7712-4bf0-dee9-9cda98fd6b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh2DkryE43ID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Credentials"
      ],
      "metadata": {
        "id": "by0sT4Ex5z3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "output in .env file:\n",
        "\n",
        "OPENAI_API_KEY=your_api_key"
      ],
      "metadata": {
        "id": "tH9hl9hi6AJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "wN3CpLqh50N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. LLM call using LangChain"
      ],
      "metadata": {
        "id": "6v7Ik0ou5brI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "cger9Y047Qo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0.0)\n",
        "chat"
      ],
      "metadata": {
        "id": "cOIuEegO50oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create a Prompt Template"
      ],
      "metadata": {
        "id": "guLc5GeL633A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "d1vIl972AKZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code=\"\"\"\n",
        "import keras\\\n",
        "from keras import layers\\\n",
        "from keras.models import Sequential\\\n",
        "def define_ae(input_shape=(1,)):\\\n",
        "    Autoencoder = Sequential()\\\n",
        "    Autoencoder.add(keras.Input(shape=input_shape))\\\n",
        "    Autoencoder.add(layers.Dense(16, activation=\"relu\"))\\\n",
        "    Autoencoder.add(layers.Dense(32, activation=\"relu\"))\\\n",
        "    Autoencoder.add(layers.Dense(input_shape[0], activation=\"sigmoid\"))\\\n",
        "    print('Autoencoder architecture: \\n')\\\n",
        "    print(Autoencoder.summary()) \\\n",
        "    return Autoencoder\\\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xJCpkEO36qAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language = \"italian\""
      ],
      "metadata": {
        "id": "23Tw9aLH60OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_string  = \"\"\"\n",
        "Explain the following Python code \\\n",
        "that is delimited by triple backticks in {language}: ```{code}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nuI-dVfR6qD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "oFYJb25g62rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmw76V5yAWJR",
        "outputId": "02dd482c-6ad0-468e-90ca-fc580c7af95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['code', 'language'], output_parser=None, partial_variables={}, template='\\nExplain the following Python code that is delimited by triple backticks in {language}: ```{code}```\\n', template_format='f-string', validate_template=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzAUSYSW-QpZ",
        "outputId": "982fadc2-6d3e-4cac-99d4-27423dc3fff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['code', 'language']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = prompt_template.format_messages(code=code,language=language)"
      ],
      "metadata": {
        "id": "ZZgTn9RO-b44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(question))\n",
        "print(type(question[0]))\n",
        "print(question[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD_icwo8AjUr",
        "outputId": "9138beb9-f8dd-4802-ce35-bcf6c68c6547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'langchain.schema.messages.HumanMessage'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(question)"
      ],
      "metadata": {
        "id": "bsaZz2bt-p3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsnZC6y5_nfB",
        "outputId": "e5b64fd7-03d2-46be-ea37-4b3e1954e242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il codice Python sopra definito è una funzione che crea un autoencoder utilizzando la libreria Keras. Un autoencoder è una rete neurale che viene addestrata per riprodurre l'input originale, cercando di comprimere e decomprimere i dati in modo efficiente.\n",
            "\n",
            "La funzione `define_ae` prende in input la forma dell'input (di default è un vettore di dimensione 1) e restituisce un modello di autoencoder.\n",
            "\n",
            "Il codice inizia importando il modulo `keras` e alcune classi specifiche da `keras.layers` e `keras.models`.\n",
            "\n",
            "Successivamente, viene definito il modello dell'autoencoder utilizzando la classe `Sequential` di Keras. La classe `Sequential` permette di creare un modello sequenziale, in cui i livelli vengono aggiunti uno dopo l'altro.\n",
            "\n",
            "Il primo livello dell'autoencoder è un livello di input, che prende in input la forma specificata. Il secondo e il terzo livello sono livelli densi (fully connected) con 16 e 32 unità rispettivamente, utilizzando la funzione di attivazione \"relu\". La funzione di attivazione \"relu\" è una funzione non lineare che viene spesso utilizzata nei livelli intermedi delle reti neurali.\n",
            "\n",
            "Il quarto e ultimo livello è un livello denso con un numero di unità uguale alla dimensione dell'input, utilizzando la funzione di attivazione \"sigmoid\". La funzione di attivazione \"sigmoid\" viene utilizzata per produrre un output compreso tra 0 e 1, che può essere interpretato come una probabilità.\n",
            "\n",
            "Infine, il codice stampa un riepilogo dell'architettura dell'autoencoder utilizzando il metodo `summary()` del modello. Questo fornisce informazioni sul numero di parametri del modello e sulle dimensioni di input e output di ciascun livello.\n",
            "\n",
            "La funzione restituisce infine il modello dell'autoencoder creato.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "language=\"english\"\n",
        "question = prompt_template.format_messages(code=code,language=language)\n",
        "response = chat(question)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFRjdBoE_8Km",
        "outputId": "e77e8b9d-bef7-4312-83b7-55e286c3cd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This Python code is defining an autoencoder using the Keras library. \n",
            "\n",
            "First, it imports the Keras library and specific modules from Keras. \n",
            "\n",
            "Then, it defines a function called `define_ae` that takes an optional argument `input_shape` with a default value of `(1,)`. \n",
            "\n",
            "Inside the function, it creates an instance of a Sequential model called `Autoencoder`. \n",
            "\n",
            "It adds layers to the `Autoencoder` model using the `add` method. The first layer is an input layer with the specified `input_shape`. \n",
            "\n",
            "The next two layers are dense layers with 16 and 32 units respectively, and they use the ReLU activation function. \n",
            "\n",
            "The final layer has the same number of units as the first dimension of the `input_shape` and uses the sigmoid activation function. \n",
            "\n",
            "After adding all the layers, it prints the summary of the `Autoencoder` model. \n",
            "\n",
            "Finally, it returns the `Autoencoder` model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = \"\"\"mlflow.sagemaker.deploy(app_name=\"ifTest\",\n",
        "    mode='create',\n",
        "    model_uri=model_uri,\n",
        "    image_url=image_url,\n",
        "    execution_role_arn=arn,\n",
        "    instance_type=\"ml.t2.medium\",\n",
        "    instance_count=1,\n",
        "    region_name=region\n",
        ")\"\"\""
      ],
      "metadata": {
        "id": "NtQHSE6OA2eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language=\"english\"\n",
        "question = prompt_template.format_messages(code=code,language=language)\n",
        "response = chat(question)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6Am5X0OBM7h",
        "outputId": "eb30134c-5023-43f5-e488-7898727295f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This Python code is using the `mlflow.sagemaker.deploy` function to deploy a machine learning model on Amazon SageMaker. \n",
            "\n",
            "The function is called with several arguments:\n",
            "\n",
            "- `app_name`: This specifies the name of the application that will be created on SageMaker.\n",
            "- `mode`: This specifies the mode of deployment. In this case, it is set to 'create', which means a new application will be created.\n",
            "- `model_uri`: This specifies the URI (Uniform Resource Identifier) of the trained model that will be deployed.\n",
            "- `image_url`: This specifies the URL of the Docker image that will be used for deployment.\n",
            "- `execution_role_arn`: This specifies the Amazon Resource Name (ARN) of the IAM role that will be used to execute the deployment.\n",
            "- `instance_type`: This specifies the type of Amazon EC2 instance that will be used for deployment. In this case, it is set to 'ml.t2.medium'.\n",
            "- `instance_count`: This specifies the number of instances that will be launched for deployment. In this case, it is set to 1.\n",
            "- `region_name`: This specifies the AWS region where the deployment will take place.\n",
            "\n",
            "Overall, this code is deploying a machine learning model on SageMaker using the specified parameters.\n"
          ]
        }
      ]
    }
  ]
}